{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02da349b-4ca8-4995-ab1d-428024cd2869",
   "metadata": {},
   "source": [
    "## Songshu Annotation via LLM (Google Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847d970-1157-4d8f-b5de-fec03d78b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "import regex as re\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53560e77-462a-4343-93e3-21c6c95b76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key from aistudio.google.com, provided you have a Google account\n",
    "GOOGLE_AI_STUDIO = ''  # <-- input your API key\n",
    "genai.configure(api_key=GOOGLE_AI_STUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfa7c4-d7b9-42f0-ade8-c31570992c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available Google AI models accessible with the API key\n",
    "for m in genai.list_models():\n",
    "    print(m.name, '\\t\\t', m.supported_generation_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82004202-5c99-4823-9dd3-95cc7fb31bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model parameters\n",
    "generation_config = {\n",
    "  \"temperature\": 0.0,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 128 * 1024,   # 128k; different LLMs have different values; check model documentation\n",
    "}\n",
    "\n",
    "# All safety settings are set to None, because I don't want any censorship\n",
    "safety_settings={\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "model_name = \"gemini-1.5-pro-latest\"    # <-- this is supposedly the best Google model (but more expensive)\n",
    "model_name = \"gemini-1.5-flash-latest\"  # <-- this is a fast (but less accurate) model\n",
    "model_name = \"gemini-1.5-pro-exp-0801\"  # <-- this is currently (Aug. 2024-08) in preview mode\n",
    "\n",
    "# Enter high-level instructions (system prompt/instruction) here (and uncomment the 'system_instruction' below)\n",
    "SYSTEM_PROMPT = '''\n",
    "[to be determined]\n",
    "'''\n",
    "\n",
    "model = genai.GenerativeModel(model_name=model_name,\n",
    "                              #system_instruction=SYSTEM_PROMPT,\n",
    "                              generation_config=generation_config,\n",
    "                              safety_settings=safety_settings\n",
    "                             )\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e42ccf-a984-4835-a363-33b30b64e661",
   "metadata": {},
   "source": [
    "### Input file to be annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4dcd2ca1-2e12-4391-8f30-505ab2e33d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file - text to be annotated\n",
    "fin = 'wudi1of3.txt'\n",
    "source_text = Path(fin).read_text(encoding='utf-8').strip().split('#####') # The delimiter ##### has been manually added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff84bd3c-a2f6-4fc0-bc50-10e28b877d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wudi1of3'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(fin).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aaf577-1d94-4492-8fc5-43813e9c7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check no. of segments and the content of the 0th segment\n",
    "len(source_text), source_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad19ba-7ec1-490c-9771-7b8b3aa001b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size (no. of characters) of each segment\n",
    "for seg in source_text:\n",
    "    print(len(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d3adb-8fa3-41c2-8a7d-539977226906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat session\n",
    "chat = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeafbaaf-0e67-406e-8fbe-3d38c8c8837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to be sent to LLM via API calls\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "You are an expert in the Classical Chinese language and ancient Chinese history, especially the Liu Song dynasty (5th century). You will be annotating a text enclosed in the <text> tag at the very end of this prompt. This is a multi-step prompt, consisting of 5 steps.\n",
    "\n",
    "=== STEPS BEGIN ===\n",
    "All of the following outputs from all steps will be enclosed in a single <segment number='{idx}'> tag.\n",
    "\n",
    "Step 1:\n",
    "Please tokenize the Classical Chinese passage into word tokens (a word can be a single-character or multi-character chunk). Simply separate the tokens using a single space. Retain the punctuation marks. Retain the empty line as a visual aid. For this step output the word-tokenized text within the tag <step1>.\n",
    "\n",
    "Step 2:\n",
    "Using the output from Step 1 (tokenized text), enclosed each word token with the XML-like tag <ne> (for named entity) only if the token is a named entity (NE), such as personal name, geographic location, date, job title, etc. Do not use a tag for a non-NE. For this step output the annotated text within the tag <step2>. \n",
    "\n",
    "Step 3:\n",
    "Using the output from Step 2, for each identified named entity within the <ne> tag, replace the <ne> tag with one of the following specific tags based on the named entity's classification:\n",
    "<p> for a personal name;\n",
    "<g> for a geographical name;\n",
    "<o> for the name of a political office or job title;\n",
    "<et> for an emperor's temple name 廟號 (e.g., 高祖);\n",
    "<ep> for an emperor's posthumous name 諡號 (e.g., 武帝);\n",
    "<era> for an imperial era name (e.g., 永初);\n",
    "<dy> for a dynastic name (e.g., 晉, 漢);\n",
    "<k> for a kinship term, such as 父, 母, 子, 女, 甥, 繼母, 從弟, 從兄, 從子, 從叔, 兄子, 弟子, 伯, 叔, 舅, 祖父, 從嫂, 從叔;\n",
    "<d> for a date or time.\n",
    "For this step output the annotated text within the tag <step3>.\n",
    "\n",
    "Step 4:\n",
    "Use the the output from Step 3, for each named entity identified as a personal name (<p>), attempt to recover the full name associated with this named entity by adding the surname; place this full name as an attribute to the <p> tag. For example, <p fn=\"劉裕\">裕<p/>, who is the founding emperor of the Liu Song Dynasty 劉裕 with the surnamed 劉. Output the entire annotated text. For a named entity identified as a date, if it is a year, attempt to prefix it with the proper era name, and place this full year designation (e.g., 永初二年, 隆安三年) as an attribute to the <d> tag, e.g., <d fd='永初二年'>二年</d>. Output the annotated text within the tag <step4>.\n",
    "\n",
    "Step 5:\n",
    "Provide a summary of the annotations made at the end within a <summary> tag.\n",
    "\n",
    "=== STEPS END ===\n",
    "\n",
    "The text to be annotated is:\n",
    "<text>\n",
    "{text_to_be_annotated}\n",
    "</text>\n",
    "\"\"\"\n",
    "\n",
    "SLEEP_TIME = 30\n",
    "\n",
    "# output file - (hopefully) annotated\n",
    "fstem = Path(fin).stem  # retrieve name of input file without file extension\n",
    "fon = f'{fstem}_annotated.{model_name}.txt'\n",
    "\n",
    "with open(fon, 'a', encoding='utf-8', newline='\\n') as fo:\n",
    "\n",
    "    for idx, src in enumerate(source_text[0:]):\n",
    "        #if idx < n: continue   # if the loop stops at Segment n, continue by uncommenting this line and change n to that Segement number \n",
    "        if src.startswith('#'): continue  # skip the #### lines\n",
    "        text_to_be_annotated = src.strip()\n",
    "\n",
    "        prompt = PROMPT.format(text_to_be_annotated=text_to_be_annotated, idx=idx)\n",
    "        print(f'Segment {idx}:') \n",
    "        print(prompt)\n",
    "\n",
    "        if idx % 2 == 0:  # clear history for every two chat.send_message() calls \n",
    "            chat = model.start_chat(history=[])\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = chat.send_message(prompt)\n",
    "        for chunk in response:\n",
    "            fo.write(chunk.text + '\\n')\n",
    "            #fo.write(\"_\"*80 + '\\n')\n",
    "        fo.flush()\n",
    "        \n",
    "        response = chat.send_message('Please continue.')  # if there are too many output tokens, we might need this prompt to force the model to complete the text-generation process\n",
    "        for chunk in response:\n",
    "            fo.write(chunk.text + '\\n')\n",
    "            fo.write(\"_\"*80 + '\\n')\n",
    "        fo.flush()\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Elapsed time for Segment {idx}: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        print('='*25)\n",
    "        print(f'**** Sleeping {SLEEP_TIME} seconds....')\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        print('**** Now continuing...')\n",
    "\n",
    "print(\"\\n\\n***** ALL DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9d729-20fe-4f1d-99db-43cd362d6b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
